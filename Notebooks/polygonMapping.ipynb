{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from pprint import pprint\n",
    "from datetime import date, timedelta, datetime\n",
    "import requests\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from shapely.geometry import mapping\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "import earthaccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-180.          -78.50015648  180.           90.00000191]\n",
      "[-180.   -55.5  180.    66.5]\n"
     ]
    }
   ],
   "source": [
    "#version of data with cleaned date ranges of sampling\n",
    "df = pd.read_csv('../agg_data_cleaned.csv')\n",
    "\n",
    "#grab unique combinations of regions and dates so that we don't need to calculation aggregations more than necessary\n",
    "sampling_df = df[['Oceanographic province', 'parsed_date']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#Pull in longhurst geometry data\n",
    "longhurst = gpd.read_file('../Savoca/Longhurst_world_v4_2010.shp')\n",
    "\n",
    "print(longhurst.total_bounds)\n",
    "longhurst = longhurst.cx[:, -37.0:37.0]\n",
    "print(longhurst.total_bounds)\n",
    "\n",
    "#Join longhurst data with sampling configurations\n",
    "sampling_df = pd.merge(sampling_df, longhurst, left_on='Oceanographic province', right_on='ProvCode', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "Load in satellite data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp_sat_data.rio.crs is not None:\n",
    "    print(f\"Dataset CRS: {mp_sat_data.rio.crs}\")\n",
    "else:\n",
    "    print(\"Dataset CRS is not set.\")\n",
    "\n",
    "mp_sat_data = mp_sat_data.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "print(longhurst.total_bounds) # Returns [minx, miny, maxx, maxy]\n",
    "\n",
    "print(f\"Latitude range: {mp_sat_data.lat.min().values} to {mp_sat_data.lat.max().values}\")\n",
    "print(f\"Longitude range: {mp_sat_data.lon.min().values} to {mp_sat_data.lon.max().values}\")\n",
    "\n",
    "mp_sat_data = mp_sat_data.assign_coords(lon=(((mp_sat_data.lon + 180) % 360) - 180)).sortby('lon')\n",
    "\n",
    "mp_sat_data = mp_sat_data.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_metrics_single(ds, row, metrics=None):\n",
    "    \"\"\"\n",
    "    Aggregates specified metrics over a single polygonal region within a dataset for a given timeframe.\n",
    "\n",
    "    Parameters:\n",
    "        ds (xarray.Dataset): The xarray dataset with spatial dimensions 'lat' and 'lon'.\n",
    "        row (pd.Series): Row containing polygon geometry, region identifier, and timeframe.\n",
    "        metrics (list of str, optional): List of metrics to aggregate (default: all in the dataset).\n",
    "\n",
    "    Returns:\n",
    "        dict: Aggregated metrics for the region in the given row.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the default metrics to all variables in the dataset if not specified\n",
    "    if metrics is None:\n",
    "        metrics = list(ds.data_vars)\n",
    "    \n",
    "    # Subset the dataset based on the specified timeframe from the row\n",
    "    timeframe = row['parsed_date']\n",
    "    start, end = timeframe\n",
    "    start = (pd.Timestamp(start) - pd.DateOffset(years=1))\n",
    "    ds_subset = ds.sel(time=slice(start, end))\n",
    "    \n",
    "    # Ensure spatial dimensions and CRS are set\n",
    "    ds_subset = ds_subset.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "    if ds_subset.rio.crs is None:\n",
    "        ds_subset = ds_subset.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    \n",
    "    # Initialize result dictionary for the current region\n",
    "    region_results = {'region': row['ProvCode']}  # Adjust 'ProvCode' to match actual identifier column name\n",
    "    \n",
    "    # Clip dataset by current polygon\n",
    "    masked_ds = ds_subset.rio.clip([mapping(row.geometry)], ds_subset.rio.crs, drop=True)\n",
    "    \n",
    "    # Aggregate each specified metric over the masked area\n",
    "    for metric in metrics:\n",
    "        #Unsure about using time here\n",
    "        mean_value = masked_ds[metric].mean(dim=['lat', 'lon', 'time'], skipna=True).compute()\n",
    "        region_results[f'mean_{metric}'] = mean_value.values\n",
    "    \n",
    "    return region_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
